{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"main page \u00b6 3blue1brown","title":"main page"},{"location":"#main-page","text":"3blue1brown","title":"main page"},{"location":"CV/","text":"MarkFeng, YoB: 1989 email: ashbringerft@gmail.com tele: +86 18510101100 Working Experience \u00b6 2022.April to now \u00b6 Honor-RD-Chip and Solution platform-ImagingAlgorithm as algorithm engineer - cellphone HDR capture algorithm develop; 2022.Feb to Mar \u00b6 Honor-RD-Camera-PictureQualtiyTuning as PQ engineer - learn Qualcomm 8450 Spectra 680 ISP Exposure tuning; 2019.Sept to 2022.Jan \u00b6 XiaoMi-Phone-Camera-ImageQualityEvlation as developer engineer - implemented and improved image quality evalution sultions @JPEG&RAW; - image sensor performance evaluation include FWC, QE, ReadNoise, FixedPatternNoise, DarkCurrent etc; built a sensor specs & minimal ISP simulation system; - model based semi/none reference based picture quality prediction; - Camera Lab automation pipeline; - VCX forum standard commitee; 2018.Apr to 2019.Aug \u00b6 PicoVR as algorithm engineer - ToF camera denoising, RGBD-IR-Depth registertion; Optical distortion and Chromatic aberration correction; - 3D Object classfication; RGB exposure correction; Distance based projector auto-focus; Education \u00b6 2012 Oct to 2017 Sept \u00b6 The University of Sheffield - Eletronic and Eletrical Engineering 2011 Sept to 2012 Sept \u00b6 The University of Sheffield - Eletronic and Eletrical Engineering 2007 to 2011 \u00b6 beijing university of technology -Eletrical Information Engineering patents \u00b6 Thesis and paper \u00b6","title":"CV"},{"location":"CV/#working-experience","text":"","title":"Working Experience"},{"location":"CV/#2022april-to-now","text":"Honor-RD-Chip and Solution platform-ImagingAlgorithm as algorithm engineer - cellphone HDR capture algorithm develop;","title":"2022.April to now"},{"location":"CV/#2022feb-to-mar","text":"Honor-RD-Camera-PictureQualtiyTuning as PQ engineer - learn Qualcomm 8450 Spectra 680 ISP Exposure tuning;","title":"2022.Feb to Mar"},{"location":"CV/#2019sept-to-2022jan","text":"XiaoMi-Phone-Camera-ImageQualityEvlation as developer engineer - implemented and improved image quality evalution sultions @JPEG&RAW; - image sensor performance evaluation include FWC, QE, ReadNoise, FixedPatternNoise, DarkCurrent etc; built a sensor specs & minimal ISP simulation system; - model based semi/none reference based picture quality prediction; - Camera Lab automation pipeline; - VCX forum standard commitee;","title":"2019.Sept to 2022.Jan"},{"location":"CV/#2018apr-to-2019aug","text":"PicoVR as algorithm engineer - ToF camera denoising, RGBD-IR-Depth registertion; Optical distortion and Chromatic aberration correction; - 3D Object classfication; RGB exposure correction; Distance based projector auto-focus;","title":"2018.Apr to 2019.Aug"},{"location":"CV/#education","text":"","title":"Education"},{"location":"CV/#2012-oct-to-2017-sept","text":"The University of Sheffield - Eletronic and Eletrical Engineering","title":"2012 Oct to 2017 Sept"},{"location":"CV/#2011-sept-to-2012-sept","text":"The University of Sheffield - Eletronic and Eletrical Engineering","title":"2011 Sept to 2012 Sept"},{"location":"CV/#2007-to-2011","text":"beijing university of technology -Eletrical Information Engineering","title":"2007 to 2011"},{"location":"CV/#patents","text":"","title":"patents"},{"location":"CV/#thesis-and-paper","text":"","title":"Thesis and paper"},{"location":"obsidian_syntax/","text":"obsidian syntax \u00b6 https://help.obsidian.md/How+to/Format+your+notes","title":"Obsidian syntax"},{"location":"obsidian_syntax/#obsidian-syntax","text":"https://help.obsidian.md/How+to/Format+your+notes","title":"obsidian syntax"},{"location":"contents/Computer_Science/Languages/Cpp/arrays%20of%20length%20zero/","text":"struct line { int length; char contents[0]; }; struct line thisline = (struct line ) malloc (sizeof (struct line) + this_length); thisline->length = this_length;","title":"Arrays of length zero"},{"location":"contents/Computer_Science/Languages/Cpp/basic/","text":"sizeof (stdio.h) fopen, flush, fclose, fseek fread fwrite fprintf fscanf printf scanf (stdlib.h) malloc free atof atoi fprintf, cout, cin","title":"Basic"},{"location":"contents/Computer_Science/Languages/Cpp/safety%20check%20void/","text":"memset; memset_s printf; printf_s","title":"Safety check void"},{"location":"contents/Computer_Science/Languages/Cpp/%E5%8F%AF%E5%8F%98%E5%85%A5%E5%8F%82/","text":"initializer_list","title":"\u53ef\u53d8\u5165\u53c2"},{"location":"contents/Computer_Science/Languages/Cpp/%E5%BC%BA%E5%88%B6%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/","text":"1\u3001\u663e\u5f0f\u5f3a\u5236\u7c7b\u578b\u8f6c\u6362 \u00b6 C\u4e2d\u663e\u5f0f\u5f3a\u5236\u7c7b\u578b\u8f6c\u6362\u5f88\u7b80\u5355\uff0c\u683c\u5f0f\u5982\u4e0b\uff1a TYPE b = (TYPE) a\uff1b \u5176\u4e2d\uff0cTYPE\u4e3a\u7c7b\u578b\u63cf\u8ff0\u7b26\uff0c\u5982int\uff0cfloat\u7b49\u3002\u7ecf\u5f3a\u5236\u7c7b\u578b\u8f6c\u6362 \u8fd0\u7b97\u7b26 \u8fd0\u7b97\u540e\uff0c\u8fd4\u56de\u4e00\u4e2a\u5177\u6709TYPE\u7c7b\u578b\u7684\u6570\u503c\uff0c\u8fd9\u79cd\u5f3a\u5236\u7c7b\u578b\u8f6c\u6362\u64cd\u4f5c\u5e76\u4e0d\u6539\u53d8 \u64cd\u4f5c\u6570 \u672c\u8eab\uff0c\u8fd0\u7b97\u540e\u64cd\u4f5c\u6570\u672c\u8eab\u672a\u6539\u53d8\uff0c\u4f8b\u5982\uff1a int n=0xab65\uff1b char a=\uff08char\uff09n\uff1b \u4e0a\u8ff0\u5f3a\u5236\u7c7b\u578b\u8f6c\u6362\u7684\u7ed3\u679c\u662f\u5c06 \u6574\u578b \u503c0xab65\u7684\u9ad8\u7aef\u4e00\u4e2a\u5b57\u8282\u5220\u6389\uff0c\u5c06\u4f4e\u7aef\u4e00\u4e2a\u5b57\u8282\u7684\u5185\u5bb9\u4f5c\u4e3achar\u578b\u6570\u503c\u8d4b\u503c\u7ed9\u53d8\u91cfa\uff0c\u800c\u7ecf\u8fc7\u7c7b\u578b\u8f6c\u6362\u540en\u7684\u503c\u5e76\u672a\u6539\u53d8\u3002 C++\u4e2d\u5f3a\u5236 \u7c7b\u578b\u8f6c\u6362\u51fd\u6570 \u67094\u4e2a\uff1aconst_cast(\u7528\u4e8e\u53bb\u9664const\u5c5e\u6027\uff09\uff0cstatic_cast(\u7528\u4e8e\u57fa\u672c\u7c7b\u578b\u7684 \u5f3a\u5236\u8f6c\u6362 \uff09\uff0c dynamic_cast (\u7528\u4e8e\u591a\u6001\u7c7b\u578b\u4e4b\u95f4\u7684\u7c7b\u578b\u8f6c\u6362\uff09\uff0creinterpreter_cast(\u7528\u4e8e\u4e0d\u540c\u7c7b\u578b\u4e4b\u95f4\u7684 \u6307\u9488 \u4e4b\u95f4\u7684\u8f6c\u6362\uff0c\u6700\u5e38\u7528\u7684\u5c31\u662f\u4e0d\u540c\u7c7b\u578b\u4e4b\u95f4 \u51fd\u6570\u6307\u9488 \u7684\u8f6c\u6362\uff09\u3002 2\u3001\u9690\u5f0f\u5f3a\u5236\u7c7b\u578b\u8f6c\u6362 \u00b6 \u9690\u5f0f\u7c7b\u578b\u8f6c\u6362\u53d1\u751f\u5728 \u8d4b\u503c\u8868\u8fbe\u5f0f \u548c\u6709\u8fd4\u56de\u503c\u7684 \u51fd\u6570\u8c03\u7528 \u8868\u8fbe\u5f0f\u4e2d\u3002\u5728\u8d4b\u503c\u8868\u8fbe\u5f0f\u4e2d\uff0c\u5982\u679c\u8d4b\u503c\u7b26\u5de6\u53f3\u4e24\u4fa7\u7684 \u64cd\u4f5c\u6570 \u7c7b\u578b\u4e0d\u540c\uff0c\u5219\u5c06\u8d4b\u503c\u7b26\u53f3\u8fb9\u64cd\u4f5c\u6570 \u5f3a\u5236\u8f6c\u6362 \u4e3a\u8d4b\u503c\u7b26\u5de6\u4fa7\u7684\u7c7b\u578b\u6570\u503c\u540e\uff0c\u8d4b\u503c\u7ed9\u8d4b\u503c\u7b26\u5de6\u4fa7\u7684\u53d8\u91cf\u3002\u5728\u51fd\u6570\u8c03\u7528\u65f6\uff0c\u5982\u679creturn\u540e\u9762 \u8868\u8fbe\u5f0f \u7684\u7c7b\u578b\u4e0e\u51fd\u6570\u8fd4\u56de\u503c\u7c7b\u578b\u4e0d\u540c\uff0c\u5219\u5728\u8fd4\u56de\u503c\u65f6\u5c06return\u540e\u9762\u8868\u8fbe\u5f0f\u7684\u6570\u503c\u5f3a\u5236\u8f6c\u6362\u4e3a\u51fd\u6570\u8fd4\u56de\u503c\u7c7b\u578b\u540e\uff0c\u518d\u5c06\u503c\u8fd4\u56de\uff0c\u5982\uff1a int n\uff1b double d=3.88\uff1b n=d\uff1b//\u6267\u884c\u672c\u53e5\u540e\uff0cn\u7684\u503c\u4e3a3\uff0c\u800cd\u7684\u503c\u4ecd\u662f3.88\u3002","title":"\u5f3a\u5236\u7c7b\u578b\u8f6c\u6362"},{"location":"contents/Computer_Science/Languages/Cpp/%E5%BC%BA%E5%88%B6%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/#1","text":"C\u4e2d\u663e\u5f0f\u5f3a\u5236\u7c7b\u578b\u8f6c\u6362\u5f88\u7b80\u5355\uff0c\u683c\u5f0f\u5982\u4e0b\uff1a TYPE b = (TYPE) a\uff1b \u5176\u4e2d\uff0cTYPE\u4e3a\u7c7b\u578b\u63cf\u8ff0\u7b26\uff0c\u5982int\uff0cfloat\u7b49\u3002\u7ecf\u5f3a\u5236\u7c7b\u578b\u8f6c\u6362 \u8fd0\u7b97\u7b26 \u8fd0\u7b97\u540e\uff0c\u8fd4\u56de\u4e00\u4e2a\u5177\u6709TYPE\u7c7b\u578b\u7684\u6570\u503c\uff0c\u8fd9\u79cd\u5f3a\u5236\u7c7b\u578b\u8f6c\u6362\u64cd\u4f5c\u5e76\u4e0d\u6539\u53d8 \u64cd\u4f5c\u6570 \u672c\u8eab\uff0c\u8fd0\u7b97\u540e\u64cd\u4f5c\u6570\u672c\u8eab\u672a\u6539\u53d8\uff0c\u4f8b\u5982\uff1a int n=0xab65\uff1b char a=\uff08char\uff09n\uff1b \u4e0a\u8ff0\u5f3a\u5236\u7c7b\u578b\u8f6c\u6362\u7684\u7ed3\u679c\u662f\u5c06 \u6574\u578b \u503c0xab65\u7684\u9ad8\u7aef\u4e00\u4e2a\u5b57\u8282\u5220\u6389\uff0c\u5c06\u4f4e\u7aef\u4e00\u4e2a\u5b57\u8282\u7684\u5185\u5bb9\u4f5c\u4e3achar\u578b\u6570\u503c\u8d4b\u503c\u7ed9\u53d8\u91cfa\uff0c\u800c\u7ecf\u8fc7\u7c7b\u578b\u8f6c\u6362\u540en\u7684\u503c\u5e76\u672a\u6539\u53d8\u3002 C++\u4e2d\u5f3a\u5236 \u7c7b\u578b\u8f6c\u6362\u51fd\u6570 \u67094\u4e2a\uff1aconst_cast(\u7528\u4e8e\u53bb\u9664const\u5c5e\u6027\uff09\uff0cstatic_cast(\u7528\u4e8e\u57fa\u672c\u7c7b\u578b\u7684 \u5f3a\u5236\u8f6c\u6362 \uff09\uff0c dynamic_cast (\u7528\u4e8e\u591a\u6001\u7c7b\u578b\u4e4b\u95f4\u7684\u7c7b\u578b\u8f6c\u6362\uff09\uff0creinterpreter_cast(\u7528\u4e8e\u4e0d\u540c\u7c7b\u578b\u4e4b\u95f4\u7684 \u6307\u9488 \u4e4b\u95f4\u7684\u8f6c\u6362\uff0c\u6700\u5e38\u7528\u7684\u5c31\u662f\u4e0d\u540c\u7c7b\u578b\u4e4b\u95f4 \u51fd\u6570\u6307\u9488 \u7684\u8f6c\u6362\uff09\u3002","title":"1\u3001\u663e\u5f0f\u5f3a\u5236\u7c7b\u578b\u8f6c\u6362"},{"location":"contents/Computer_Science/Languages/Cpp/%E5%BC%BA%E5%88%B6%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/#2","text":"\u9690\u5f0f\u7c7b\u578b\u8f6c\u6362\u53d1\u751f\u5728 \u8d4b\u503c\u8868\u8fbe\u5f0f \u548c\u6709\u8fd4\u56de\u503c\u7684 \u51fd\u6570\u8c03\u7528 \u8868\u8fbe\u5f0f\u4e2d\u3002\u5728\u8d4b\u503c\u8868\u8fbe\u5f0f\u4e2d\uff0c\u5982\u679c\u8d4b\u503c\u7b26\u5de6\u53f3\u4e24\u4fa7\u7684 \u64cd\u4f5c\u6570 \u7c7b\u578b\u4e0d\u540c\uff0c\u5219\u5c06\u8d4b\u503c\u7b26\u53f3\u8fb9\u64cd\u4f5c\u6570 \u5f3a\u5236\u8f6c\u6362 \u4e3a\u8d4b\u503c\u7b26\u5de6\u4fa7\u7684\u7c7b\u578b\u6570\u503c\u540e\uff0c\u8d4b\u503c\u7ed9\u8d4b\u503c\u7b26\u5de6\u4fa7\u7684\u53d8\u91cf\u3002\u5728\u51fd\u6570\u8c03\u7528\u65f6\uff0c\u5982\u679creturn\u540e\u9762 \u8868\u8fbe\u5f0f \u7684\u7c7b\u578b\u4e0e\u51fd\u6570\u8fd4\u56de\u503c\u7c7b\u578b\u4e0d\u540c\uff0c\u5219\u5728\u8fd4\u56de\u503c\u65f6\u5c06return\u540e\u9762\u8868\u8fbe\u5f0f\u7684\u6570\u503c\u5f3a\u5236\u8f6c\u6362\u4e3a\u51fd\u6570\u8fd4\u56de\u503c\u7c7b\u578b\u540e\uff0c\u518d\u5c06\u503c\u8fd4\u56de\uff0c\u5982\uff1a int n\uff1b double d=3.88\uff1b n=d\uff1b//\u6267\u884c\u672c\u53e5\u540e\uff0cn\u7684\u503c\u4e3a3\uff0c\u800cd\u7684\u503c\u4ecd\u662f3.88\u3002","title":"2\u3001\u9690\u5f0f\u5f3a\u5236\u7c7b\u578b\u8f6c\u6362"},{"location":"contents/Computer_Science/Languages/Python/syntax/","text":"dict; \u00b6 decorator; \u00b6 yield; \u00b6","title":"Syntax"},{"location":"contents/Computer_Science/Languages/Python/syntax/#dict","text":"","title":"dict;"},{"location":"contents/Computer_Science/Languages/Python/syntax/#decorator","text":"","title":"decorator;"},{"location":"contents/Computer_Science/Languages/Python/syntax/#yield","text":"","title":"yield;"},{"location":"contents/Computer_Science/Languages/Python/underscore/","text":"_: temp var, _x: private var; __x: auto rename var; x_: avoid repeat var; __x__: default magic methods; _x__x:","title":"Underscore"},{"location":"contents/Computer_Science/Operation_System/%E6%AF%94%E8%BE%83%E5%99%A8/","text":"","title":"\u6bd4\u8f83\u5668"},{"location":"contents/Computer_Vision/Calibration/","text":"","title":"Calibration"},{"location":"contents/Computer_Vision/Camera_Model/","text":"","title":"Camera Model"},{"location":"contents/Computer_Vision/Classfication/","text":"","title":"Classfication"},{"location":"contents/Computer_Vision/Descriptors/","text":"","title":"Descriptors"},{"location":"contents/Computer_Vision/Keypoints/","text":"","title":"Keypoints"},{"location":"contents/Computer_Vision/control/","text":"kalman filter","title":"Control"},{"location":"contents/Deep_Learning/abstracts/","text":"backbone bottom neck","title":"Abstracts"},{"location":"contents/Deep_Learning/activation/","text":"","title":"Activation"},{"location":"contents/Deep_Learning/datasets/","text":"ImageNet CoCo KITTI face in the wild HDR adobe 5k, HDRNet;","title":"Datasets"},{"location":"contents/Deep_Learning/loss/","text":"focal loss VGG loss","title":"Loss"},{"location":"contents/Deep_Learning/net/","text":"","title":"Net"},{"location":"contents/Deep_Learning/norms/","text":"switchable-normalization: \u81ea\u52a8\u53ef\u5fae\u7684w1 BatchNorm+w2 InstanceNorm+w3*LayerNorm","title":"Norms"},{"location":"contents/Deep_Learning/optimizer/","text":"sgd; adam; momentum;","title":"Optimizer"},{"location":"contents/Deep_Learning/upscale/","text":"upscale: w,h,c --> w*r, h*r, c deconv: [ h1=w2*w1 ] \\(\\dots\\) [ h2=w1*h2 ] --> w1*h2 pixelShuffle: w,h,1 --> w,h,r*r -->w*r, h*r, 1","title":"Upscale"},{"location":"contents/Deep_Learning/platforms/pytorch/","text":"","title":"Pytorch"},{"location":"contents/Deep_Learning/platforms/tensorflow/","text":"keras model.add","title":"Tensorflow"},{"location":"contents/Digital_Image_Processing/Color_Space/","text":"","title":"Color Space"},{"location":"contents/Digital_Image_Processing/Compression/","text":"","title":"Compression"},{"location":"contents/Digital_Image_Processing/filtering/BM3D/","text":"Image denoising by sparse 3d transformdomain collaborative filtering An Analysis and Implementation of the BM3D Image Denoising Method","title":"BM3D"},{"location":"contents/Digital_Image_Processing/filtering/bilateral_filter/","text":"bilateral filter \u00b6 \u6587\u7ae0 \u00b6 @inproceedings{2002Bilateral, title={Bilateral filtering for gray and color images}, author={ Tomasi, C. and Manduchi, R. }, booktitle={International Conference on Computer Vision}, year={2002}, } - Fast O(1) bilateral \ufb01ltering using trigonometric range kernels - \u6838\u5fc3\u516c\u5f0f \u00b6 \\[I(x,y)'=G_s(I(x,y))*G_i(I(x,y))\\] \\( \\(pixel_{sum} = \\sum_{p\\in block}I(x,y)*weight(x,y)\\) \\) \\( \\(weight_{sum} = \\sum_{p\\in block}G_i(I(x,y)-I(x',y')) * G_s(\\sqrt{(x'-x)^2+(y'-y)^2})\\) \\) \u5b9e\u73b0 \u00b6 import cv2 import numpy as np from tqdm import tqdm \"\"\" naive implement \"\"\" def gaussian(x, sigma): return (1.0/ \\ (2 * np.pi * (sigma**2))) \\ * np.exp(-(x**2)/ \\ 2 * (sigma**2)) def distance(x1, y1, x2, y2): return np.sqrt(np.abs((x1-x2)**2 \\ -(y1-y2)**2) ) def bilateral_filter(image, diameter, sigma_i, sigma_s): new_image = np.zeros(image.shape) for row in tqdm(range(len(image))): print('row ', row) for col in range(len(image[0])): wp_total = 0 filtered_image = 0 for k in range(diameter): for l in range(diameter): n_x = row - (diameter/2 - k) n_y = col - (diameter/2 - l) if n_x >= len(image): n_x -= len(image) if n_y >= len(image[0]): n_y -= len(image[0]) gi = gaussian(image[int(n_x)][int(n_y)] - image[row][col], sigma_i) gs = gaussian(distance(n_x, n_y, row, col), sigma_s) wp = gi * gs filtered_image = (filtered_image) + (image[int(n_x)][int(n_y)] * wp) wp_total = wp_total + wp filtered_image = filtered_image // wp_total new_image[row, col] = int(np.round(filtered_image)) return new_image \"\"\" speed up \"\"\" \"\"\" 1 window gaissian LUT \"\"\" \"\"\" 2 intensity gaussian LUT \"\"\" \"\"\" 3 window LUT \"\"\" diameter, sigma_s, sigma_i = 7, 0.1, 0.1 gi_lut = gaussian(np.arange(0-255, 0+255, 1), sigma = sigma_i) gs_lut = gaussian(np.arange(0, 0+diameter, 1), sigma = sigma_s) #window_lut = np.zeros((image.shape[1], image.shape[0], diameter**2)) window_index = diameter >> 1 map = np.meshgrid(np.linspace(-window_index, window_index, window_index * 2 + 1), \\ np.linspace(-window_index, window_index, window_index * 2 + 1)) map[0], map[1] = map[0].astype(np.int), map[1].astype(np.int) gs_weights2d = gaussian(distance(map[0].flatten(), map[1].flatten(), 0, 0), sigma_s) def bilateral_filter_lut(image, diameter, gs_lut, gi_lut): new_image = np.zeros(image.shape) for row in tqdm(range( window_index, image.shape[0] - window_index, 1)): for col in range( window_index, image.shape[1] - window_index, 1): values = image[ row + map[0].flatten(), col + map[1].flatten()] gi = gi_lut[values - image[row, col] + 255 - 1] wp = gi * gs_weights2d pixel = np.sum((values * wp)) / (np.sum(wp)) #if abs(pixel-image[row, col]) > 10: # print('pixel old ', image[row, col], 'pixel new ', pixel) new_image[row, col] = int(np.round(pixel)) return new_image \"\"\" joint bilateral filter \"\"\" \"\"\" bilateral upsampling \"\"\" \"\"\" todo histogram optimization \"\"\" image = cv2.imread(\"in_img.jpg\",0) #filtered_image_OpenCV = cv2.bilateralFilter(image, 7, 20.0, 20.0) #cv2.imwrite(\"filtered_image_OpenCV.png\", filtered_image_OpenCV) #image_own = bilateral_filter_lut(image, 7, 20.0, 20.0) image_own = bilateral_filter_lut(image, diameter, gs_lut, gi_lut) cv2.imwrite(\"filtered_image_own.png\", image_own) cv2.imwrite(\"diff.png\", abs(image - image_own)*5) \"\"\" The bilateral filter is controlled by important parameters. Two of them are sigma values. Generally, the bilateral filter gives us more control over image. If we increment both sigma values at the same time, the bigger sigma values gives us a more blurred image. If we give sigma values near zero, smoothing does not occur. Changing sigma i directly affects the blur effect on the image. However, sigma s does not affect blur rate. There is no big effect on the image after changing only the sigma s. Sharpness does not necessary that much with sigma s rather than sigma i. To have a more blurred image, we should take sigma values bigger. \"\"\"","title":"Bilateral filter"},{"location":"contents/Digital_Image_Processing/filtering/bilateral_filter/#bilateral-filter","text":"","title":"bilateral filter"},{"location":"contents/Digital_Image_Processing/filtering/bilateral_filter/#_1","text":"@inproceedings{2002Bilateral, title={Bilateral filtering for gray and color images}, author={ Tomasi, C. and Manduchi, R. }, booktitle={International Conference on Computer Vision}, year={2002}, } - Fast O(1) bilateral \ufb01ltering using trigonometric range kernels -","title":"\u6587\u7ae0"},{"location":"contents/Digital_Image_Processing/filtering/bilateral_filter/#_2","text":"\\[I(x,y)'=G_s(I(x,y))*G_i(I(x,y))\\] \\( \\(pixel_{sum} = \\sum_{p\\in block}I(x,y)*weight(x,y)\\) \\) \\( \\(weight_{sum} = \\sum_{p\\in block}G_i(I(x,y)-I(x',y')) * G_s(\\sqrt{(x'-x)^2+(y'-y)^2})\\) \\)","title":"\u6838\u5fc3\u516c\u5f0f"},{"location":"contents/Digital_Image_Processing/filtering/bilateral_filter/#_3","text":"import cv2 import numpy as np from tqdm import tqdm \"\"\" naive implement \"\"\" def gaussian(x, sigma): return (1.0/ \\ (2 * np.pi * (sigma**2))) \\ * np.exp(-(x**2)/ \\ 2 * (sigma**2)) def distance(x1, y1, x2, y2): return np.sqrt(np.abs((x1-x2)**2 \\ -(y1-y2)**2) ) def bilateral_filter(image, diameter, sigma_i, sigma_s): new_image = np.zeros(image.shape) for row in tqdm(range(len(image))): print('row ', row) for col in range(len(image[0])): wp_total = 0 filtered_image = 0 for k in range(diameter): for l in range(diameter): n_x = row - (diameter/2 - k) n_y = col - (diameter/2 - l) if n_x >= len(image): n_x -= len(image) if n_y >= len(image[0]): n_y -= len(image[0]) gi = gaussian(image[int(n_x)][int(n_y)] - image[row][col], sigma_i) gs = gaussian(distance(n_x, n_y, row, col), sigma_s) wp = gi * gs filtered_image = (filtered_image) + (image[int(n_x)][int(n_y)] * wp) wp_total = wp_total + wp filtered_image = filtered_image // wp_total new_image[row, col] = int(np.round(filtered_image)) return new_image \"\"\" speed up \"\"\" \"\"\" 1 window gaissian LUT \"\"\" \"\"\" 2 intensity gaussian LUT \"\"\" \"\"\" 3 window LUT \"\"\" diameter, sigma_s, sigma_i = 7, 0.1, 0.1 gi_lut = gaussian(np.arange(0-255, 0+255, 1), sigma = sigma_i) gs_lut = gaussian(np.arange(0, 0+diameter, 1), sigma = sigma_s) #window_lut = np.zeros((image.shape[1], image.shape[0], diameter**2)) window_index = diameter >> 1 map = np.meshgrid(np.linspace(-window_index, window_index, window_index * 2 + 1), \\ np.linspace(-window_index, window_index, window_index * 2 + 1)) map[0], map[1] = map[0].astype(np.int), map[1].astype(np.int) gs_weights2d = gaussian(distance(map[0].flatten(), map[1].flatten(), 0, 0), sigma_s) def bilateral_filter_lut(image, diameter, gs_lut, gi_lut): new_image = np.zeros(image.shape) for row in tqdm(range( window_index, image.shape[0] - window_index, 1)): for col in range( window_index, image.shape[1] - window_index, 1): values = image[ row + map[0].flatten(), col + map[1].flatten()] gi = gi_lut[values - image[row, col] + 255 - 1] wp = gi * gs_weights2d pixel = np.sum((values * wp)) / (np.sum(wp)) #if abs(pixel-image[row, col]) > 10: # print('pixel old ', image[row, col], 'pixel new ', pixel) new_image[row, col] = int(np.round(pixel)) return new_image \"\"\" joint bilateral filter \"\"\" \"\"\" bilateral upsampling \"\"\" \"\"\" todo histogram optimization \"\"\" image = cv2.imread(\"in_img.jpg\",0) #filtered_image_OpenCV = cv2.bilateralFilter(image, 7, 20.0, 20.0) #cv2.imwrite(\"filtered_image_OpenCV.png\", filtered_image_OpenCV) #image_own = bilateral_filter_lut(image, 7, 20.0, 20.0) image_own = bilateral_filter_lut(image, diameter, gs_lut, gi_lut) cv2.imwrite(\"filtered_image_own.png\", image_own) cv2.imwrite(\"diff.png\", abs(image - image_own)*5) \"\"\" The bilateral filter is controlled by important parameters. Two of them are sigma values. Generally, the bilateral filter gives us more control over image. If we increment both sigma values at the same time, the bigger sigma values gives us a more blurred image. If we give sigma values near zero, smoothing does not occur. Changing sigma i directly affects the blur effect on the image. However, sigma s does not affect blur rate. There is no big effect on the image after changing only the sigma s. Sharpness does not necessary that much with sigma s rather than sigma i. To have a more blurred image, we should take sigma values bigger. \"\"\"","title":"\u5b9e\u73b0"},{"location":"contents/Digital_Image_Processing/filtering/filtering/","text":"TOC \u00b6 linear box gaussian bilateral bilateral_filter non local mean guided nonlinear median trilateral optimization wiener BM3D TV, L1 and L0","title":"Filtering"},{"location":"contents/Digital_Image_Processing/filtering/filtering/#toc","text":"linear box gaussian bilateral bilateral_filter non local mean guided nonlinear median trilateral optimization wiener BM3D TV, L1 and L0","title":"TOC"},{"location":"contents/Digital_Image_Processing/filtering/wiener_filter/","text":"A TRUE WIENER FILTER IMPLEMENTATION FOR IMPROVING SIGNAL TO NOISE AND RESOLUTION IN ACOUSTIC IMAGES \u6838\u5fc3\u516c\u5f0f \u00b6 \\( \\(g=f*h+n\\) \\) \\( \\(R=\\frac{H^{*}}{|H|^{2}+Sn/Sf}\\) \\) \u5b9e\u73b0 \u00b6 Yf = fft2(y); Hf = fft2(h,N,N); Pyf = abs(Yf).^2/N^2; % direct implementation of the regularized inverse filter, % when alpha = 1, it is the Wiener filter % Gf = conj(Hf).*Pxf./(abs(Hf.^2).*Pxf+alpha*sigma^2); % Since we don't know Pxf, the following % handle singular case (zero case) sHf = Hf.*(abs(Hf)>0)+1/gamma*(abs(Hf)==0); iHf = 1./sHf; iHf = iHf.*(abs(Hf)*gamma>1)+gamma*abs(sHf).*iHf.*(abs(sHf)*gamma<=1); Pyf = Pyf.*(Pyf>sigma^2)+sigma^2*(Pyf<=sigma^2); Gf = iHf.*(Pyf-sigma^2)./(Pyf-(1-alpha)*sigma^2); % max(max(abs(Gf).^2)) % should be equal to gamma^2 % Restorated image without denoising eXf = Gf.*Yf; ex = real(ifft2(eXf)); def wiener_filter(img, kernel, K): kernel /= np.sum(kernel) dummy = np.copy(img) dummy = fft2(dummy) kernel = fft2(kernel, s = img.shape) kernel = np.conj(kernel) / (np.abs(kernel) ** 2 + K) dummy = dummy * kernel dummy = np.abs(ifft2(dummy)) return dummy","title":"Wiener filter"},{"location":"contents/Digital_Image_Processing/filtering/wiener_filter/#_1","text":"\\( \\(g=f*h+n\\) \\) \\( \\(R=\\frac{H^{*}}{|H|^{2}+Sn/Sf}\\) \\)","title":"\u6838\u5fc3\u516c\u5f0f"},{"location":"contents/Digital_Image_Processing/filtering/wiener_filter/#_2","text":"Yf = fft2(y); Hf = fft2(h,N,N); Pyf = abs(Yf).^2/N^2; % direct implementation of the regularized inverse filter, % when alpha = 1, it is the Wiener filter % Gf = conj(Hf).*Pxf./(abs(Hf.^2).*Pxf+alpha*sigma^2); % Since we don't know Pxf, the following % handle singular case (zero case) sHf = Hf.*(abs(Hf)>0)+1/gamma*(abs(Hf)==0); iHf = 1./sHf; iHf = iHf.*(abs(Hf)*gamma>1)+gamma*abs(sHf).*iHf.*(abs(sHf)*gamma<=1); Pyf = Pyf.*(Pyf>sigma^2)+sigma^2*(Pyf<=sigma^2); Gf = iHf.*(Pyf-sigma^2)./(Pyf-(1-alpha)*sigma^2); % max(max(abs(Gf).^2)) % should be equal to gamma^2 % Restorated image without denoising eXf = Gf.*Yf; ex = real(ifft2(eXf)); def wiener_filter(img, kernel, K): kernel /= np.sum(kernel) dummy = np.copy(img) dummy = fft2(dummy) kernel = fft2(kernel, s = img.shape) kernel = np.conj(kernel) / (np.abs(kernel) ** 2 + K) dummy = dummy * kernel dummy = np.abs(ifft2(dummy)) return dummy","title":"\u5b9e\u73b0"},{"location":"contents/Digital_Signal_Processing/Transforms/","text":"DFT DCT DST DWT KLT FFT \u00b6 \u6838\u5fc3\u6982\u5ff5: - \u591a\u9879\u5f0f\u4e58\u6cd5, \u7cfb\u6570-\u6570\u503c - \u5947\u51fd\u6570\u5076\u51fd\u6570 - \u9012\u5f52&\u590d\u6570\u5e73\u65b9, \u6b27\u62c9\u516c\u5f0f [scripts]https://www.geeksforgeeks.org/fast-fourier-transformation-poynomial-multiplication/","title":"Transforms"},{"location":"contents/Digital_Signal_Processing/Transforms/#fft","text":"\u6838\u5fc3\u6982\u5ff5: - \u591a\u9879\u5f0f\u4e58\u6cd5, \u7cfb\u6570-\u6570\u503c - \u5947\u51fd\u6570\u5076\u51fd\u6570 - \u9012\u5f52&\u590d\u6570\u5e73\u65b9, \u6b27\u62c9\u516c\u5f0f [scripts]https://www.geeksforgeeks.org/fast-fourier-transformation-poynomial-multiplication/","title":"FFT"},{"location":"contents/Human_Visual_System/Color_Space/","text":"","title":"Color Space"},{"location":"contents/Human_Visual_System/VIsual_Saliency/","text":"","title":"VIsual Saliency"},{"location":"contents/Image_Qualty_Assessment/Full_Reference/","text":"","title":"Full Reference"},{"location":"contents/Image_Qualty_Assessment/No_Reference/","text":"","title":"No Reference"},{"location":"contents/Image_Qualty_Assessment/Semi_Reference/","text":"","title":"Semi Reference"},{"location":"contents/Machine_Learning/Classfication/","text":"","title":"Classfication"},{"location":"contents/Machine_Learning/classifers/Support_Vector_Machine/","text":"KKT \u51e0\u4f55\u610f\u4e49 \u6838\u51fd\u6570 \u7ebf\u6027 Radial basis function \u5f84\u5411\u57fa, \u9ad8\u65af \\(K(x,x')=exp(-\\frac{\\lvert{x-x'}\\rvert_{2}^{2}}{2\\sigma^2})\\) \u591a\u9879\u5f0f sigmoid \\(K(x,x')=tanh(a*x^Tx_i+b)\\) chi-squared \u5361\u65b9","title":"Support Vector Machine"},{"location":"contents/Mathmatics/norm/","text":"","title":"Norm"},{"location":"contents/Mathmatics/optimization/","text":"","title":"Optimization"},{"location":"contents/Mathmatics/Linear_Algebra/inverse_matrix/","text":"\u9ad8\u65af\u6d88\u5143 LU\u5206\u89e3 QR\u5206\u89e3 SVD\u5206\u89e3","title":"Inverse matrix"},{"location":"contents/Physic_Subjects/Lens/","text":"","title":"Lens"},{"location":"contents/Physic_Subjects/Light/","text":"\u591a\u5149\u8c31 \u80fd\u91cf\uff0c\u534a\u5cf0 \u5149\u8c31\u5206\u8fa8\u7387 \u4fe1\u566a\u6bd4 \u54cd\u5e94\u7ebf\u6027\u5ea6 \u666e\u6717\u514b\uff0c \u73bb\u5c14\u5179\u66fc\uff0c","title":"Light"},{"location":"contents/Physic_Subjects/Sensor/","text":"","title":"Sensor"},{"location":"contents/Physic_Subjects/illumination%20photometry/","text":"","title":"Illumination photometry"},{"location":"contents/interesting/AppleProRaw/","text":"the JPG and masks are stored with subIFDs; the RAW is stored as 12bit and with a 12to16 LUT; @python import os from tqdm import tqdm def jpg_from_dng(src, dst): with open(src, 'rb') as fid: data = fid.read() counter, bool_s, bool_e = 0, 0, 0 for i in tqdm(range(len(str(data)))): # JPG header start hex if data[i:i+4] == b'\\xff\\xd8\\xff\\xe0': index_s, bool_s = i, 1 # JPG header end hex if data[i:i+2] == b'\\xff\\xd9': index_e, bool_e =i, 1 if bool_s == 1 and bool_e == 1: bool_s, bool_e = 0, 0 with open(os.path.join(dst, 'dump_' + str(counter) + '.jpg'), 'wb') as fout: fout.write(data[index_s: index_e + 2]) counter += 1 jpg_from_dng(r\" \", r\" \")","title":"AppleProRaw"},{"location":"contents/%E6%9D%82%E5%AD%A6/cooking/%E7%AE%80%E5%8D%95%E6%A6%82%E5%BF%B5/","text":"\u7f8e\u62c9\u5fb7\u53cd\u5e94: \u6307\u7684\u662f\u98df\u7269\u4e2d\u7684\u8fd8\u539f\u7cd6\uff08\u78b3\u6c34\u5316\u5408\u7269\uff09\u4e0e\u6c28\u57fa\u9178\uff0f\u86cb\u767d\u8d28\u5728\u5e38\u6e29\u6216\u52a0\u70ed\u65f6\u53d1\u751f\u7684\u4e00\u7cfb\u5217\u590d\u6742\u53cd\u5e94\uff0c\u5176\u7ed3\u679c\u662f\u751f\u6210\u4e86\u68d5\u9ed1\u8272\u7684\u5927\u5206\u5b50\u7269\u8d28\u7c7b\u9ed1\u7cbe\u6216\u79f0\u62df\u9ed1\u7d20\u3002 \u9c9c\u5473: \u8c37\u6c28\u9178\u94a0 \u86cb\u767d\u8d28\u53d8\u6027-\u6c34\u89e3\u591a\u80bd-\u6c34\u89e3\u6c28\u57fa\u9178","title":"\u7b80\u5355\u6982\u5ff5"},{"location":"contents/%E6%9D%82%E5%AD%A6/%E7%96%AB%E8%8B%97/%E7%96%AB%E8%8B%97%E7%9A%84%E7%A7%8D%E7%B1%BB/","text":"\u51cf\u6bd2\u75ab\u82d7 \u706d\u6d3b\u75ab\u82d7 \u7c7b\u6bd2\u7d20\u75ab\u82d7 \u4e9a\u5355\u4f4d\u75ab\u82d7 \u6838\u9178\u75ab\u82d7 mRNA DNA","title":"\u75ab\u82d7\u7684\u79cd\u7c7b"},{"location":"contents/%E6%9D%82%E5%AD%A6/%E7%BB%8F%E6%B5%8E%E5%AD%A6%E5%90%8D%E8%AF%8D/%E7%AE%80%E5%8D%95%E6%A6%82%E5%BF%B5/","text":"GDP CPI \u52a0\u606f \u7f29\u8868 \u901a\u8d27\u81a8\u80c0 \u91cf\u5316\u5bbd\u677e \u7f8e\u8054\u50a8","title":"\u7b80\u5355\u6982\u5ff5"},{"location":"link/cheatsheets/","text":"","title":"Cheatsheets"},{"location":"link/knowledge_graph/","text":"knowledge_graph","title":"Knowledge graph"},{"location":"link/papers/","text":"@inproceedings{li2019blind, title={Blind Geometric Distortion Correction on Images Through Deep Learning}, author={Li, Xiaoyu and Zhang, Bo and Sander, Pedro V and Liao, Jing}, booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pages={4855--4864}, year={2019} }","title":"Papers"},{"location":"link/projects/","text":"","title":"Projects"},{"location":"link/reading/","text":"CVPR NIPS, ICLR, AAAI, ICML ICCV, ECCV TIP, TOG, SIGGRAPH arXiv ICASSP, ICIP, ICME","title":"Reading"},{"location":"link/researchers/","text":"mantiuk reinhard MPI \u7f57\u6559\u6388 \u6d59\u5927","title":"Researchers"},{"location":"notes/daliy_notes/2022_May/","text":"20220528 \u00b6 [ ] use MathJax render eqaution [https://mkdocs-material.zimoapps.com/reference/mathjax/] 20220526 \u00b6 arbitary style transfer in real-time with adaptive instance normalization controlling perceptual factors in neural style tranfer joint bilateral learning for real time universal photorealistic style tranfer 20220517 \u00b6 [ ] update bilateral page; datasets; 20220515 \u00b6 [ ] bliateral filter, bilteral joint filter, bilateral upsampling; filtering [ ] DNN STOA paper update; [ ] update CV; 20220514 \u00b6 [x] update obsidian skeleton; [x] Apple ProRaw lossy jpg extract fron DNG; AppleProRaw","title":"2022 May"},{"location":"notes/daliy_notes/2022_May/#20220528","text":"[ ] use MathJax render eqaution [https://mkdocs-material.zimoapps.com/reference/mathjax/]","title":"20220528"},{"location":"notes/daliy_notes/2022_May/#20220526","text":"arbitary style transfer in real-time with adaptive instance normalization controlling perceptual factors in neural style tranfer joint bilateral learning for real time universal photorealistic style tranfer","title":"20220526"},{"location":"notes/daliy_notes/2022_May/#20220517","text":"[ ] update bilateral page; datasets;","title":"20220517"},{"location":"notes/daliy_notes/2022_May/#20220515","text":"[ ] bliateral filter, bilteral joint filter, bilateral upsampling; filtering [ ] DNN STOA paper update; [ ] update CV;","title":"20220515"},{"location":"notes/daliy_notes/2022_May/#20220514","text":"[x] update obsidian skeleton; [x] Apple ProRaw lossy jpg extract fron DNG; AppleProRaw","title":"20220514"},{"location":"papers/DNN/","text":"Note 3 \u00b6","title":"Note 3"},{"location":"papers/DNN/#note-3","text":"","title":"Note 3"},{"location":"papers/HDR/","text":"Note 4 \u00b6 HDRNet","title":"Note 4"},{"location":"papers/HDR/#note-4","text":"HDRNet","title":"Note 4"},{"location":"papers/Image_Quality_Assessment/","text":"","title":"Image Quality Assessment"},{"location":"papers/to%20be%20read/","text":"","title":"To be read"},{"location":"papers/tonemapping_nets/list/","text":"HDRNet Zero-Reference Deep Curve Estimation for Low-Light Image Enhancement Underexposed Photo Enhancement using Deep Illumination Estimation","title":"List"}]}